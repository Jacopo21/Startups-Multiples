{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  \n",
    "\n",
    "SEED = 42\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "PATIENCE = 15\n",
    "REDUCE_LR_PATIENCE = 5\n",
    "MIN_LR = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\JacopoBinati\\OneDrive - Venionaire Capital\\Desktop\\crunchbase\\dataset.csv\")\n",
    "df.drop(columns=[\n",
    "    \"EV/Sales\",\n",
    "    \"ROE\",\n",
    "    \"Expected growth - next 5 years\",\n",
    "    \"Forward PE\",\n",
    "    \"% of Money Losing firms (Trailing)\",\n",
    "], inplace=True)\n",
    "\n",
    "X = df.drop('normalized_valuation', axis=1)\n",
    "\n",
    "y = df['normalized_valuation']\n",
    "\n",
    "categorical_variables = {\n",
    "    'Industry': [col for col in X.columns if col.startswith('Industry_')],\n",
    "    'Region': [col for col in X.columns if col.startswith('Region_')],\n",
    "    'Last Funding Type': [col for col in X.columns if col.startswith('LastFundingType__')],\n",
    "    'All Funding Type': [col for col in X.columns if col.startswith('FundingType__')],\n",
    "    'size of the company': [col for col in X.columns if col.startswith('NumberEmployees__')]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17924, 165)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Number of Founders',\n",
       " 'Number of Funding Rounds',\n",
       " 'Last Funding Amount (in USD)',\n",
       " 'Last Equity Funding Amount (in USD)',\n",
       " 'Total Equity Funding Amount (in USD)',\n",
       " 'Total Funding Amount (in USD)',\n",
       " 'Number of Investors',\n",
       " 'Number of Investments',\n",
       " 'Last Funding Year',\n",
       " 'Founded Year',\n",
       " 'Status__Private',\n",
       " 'CompanyType__For Profit',\n",
       " 'CompanyType__Non-profit',\n",
       " 'NumberEmployees__1-10',\n",
       " 'NumberEmployees__10001+',\n",
       " 'NumberEmployees__1001-5000',\n",
       " 'NumberEmployees__101-250',\n",
       " 'NumberEmployees__11-50',\n",
       " 'NumberEmployees__251-500',\n",
       " 'NumberEmployees__5001-10000',\n",
       " 'NumberEmployees__501-1000',\n",
       " 'NumberEmployees__51-100',\n",
       " 'FundingType__Angel',\n",
       " 'FundingType__Convertible Note',\n",
       " 'FundingType__Corporate Round',\n",
       " 'FundingType__Debt Financing',\n",
       " 'FundingType__Equity Crowdfunding',\n",
       " 'FundingType__Grant',\n",
       " 'FundingType__Initial Coin Offering',\n",
       " 'FundingType__Non-equity Assistance',\n",
       " 'FundingType__Post-IPO Debt',\n",
       " 'FundingType__Post-IPO Equity',\n",
       " 'FundingType__Post-IPO Secondary',\n",
       " 'FundingType__Pre-Seed',\n",
       " 'FundingType__Private Equity',\n",
       " 'FundingType__Product Crowdfunding',\n",
       " 'FundingType__Secondary Market',\n",
       " 'FundingType__Seed',\n",
       " 'FundingType__Series A',\n",
       " 'FundingType__Series B',\n",
       " 'FundingType__Series C',\n",
       " 'FundingType__Series D',\n",
       " 'FundingType__Series E',\n",
       " 'FundingType__Series F',\n",
       " 'FundingType__Series G',\n",
       " 'FundingType__Series H',\n",
       " 'FundingType__Series I',\n",
       " 'FundingType__Series J',\n",
       " 'FundingType__Undisclosed',\n",
       " 'FundingType__Venture - Series Unknown',\n",
       " 'Industry_Aerospace/Defense',\n",
       " 'Industry_Air Transport',\n",
       " 'Industry_Apparel',\n",
       " 'Industry_Auto & Truck',\n",
       " 'Industry_Auto Parts',\n",
       " 'Industry_Bank (Money Center)',\n",
       " 'Industry_Banks (Regional)',\n",
       " 'Industry_Beverage (Soft)',\n",
       " 'Industry_Brokerage & Investment Banking',\n",
       " 'Industry_Building Materials',\n",
       " 'Industry_Business & Consumer Services',\n",
       " 'Industry_Chemical (Basic)',\n",
       " 'Industry_Chemical (Diversified)',\n",
       " 'Industry_Chemical (Specialty)',\n",
       " 'Industry_Coal & Related Energy',\n",
       " 'Industry_Computer Services',\n",
       " 'Industry_Computers/Peripherals',\n",
       " 'Industry_Diversified',\n",
       " 'Industry_Drugs (Biotechnology)',\n",
       " 'Industry_Drugs (Pharmaceutical)',\n",
       " 'Industry_Education',\n",
       " 'Industry_Electrical Equipment',\n",
       " 'Industry_Electronics (Consumer & Office)',\n",
       " 'Industry_Electronics (General)',\n",
       " 'Industry_Engineering/Construction',\n",
       " 'Industry_Entertainment',\n",
       " 'Industry_Environmental & Waste Services',\n",
       " 'Industry_Farming/Agriculture',\n",
       " 'Industry_Financial Svcs. (Non-bank & Insurance)',\n",
       " 'Industry_Food Processing',\n",
       " 'Industry_Food Wholesalers',\n",
       " 'Industry_Green & Renewable Energy',\n",
       " 'Industry_Healthcare Support Services',\n",
       " 'Industry_Heathcare Information and Technology',\n",
       " 'Industry_Homebuilding',\n",
       " 'Industry_Hotel/Gaming',\n",
       " 'Industry_Household Products',\n",
       " 'Industry_Information Services',\n",
       " 'Industry_Insurance (General)',\n",
       " 'Industry_Investments & Asset Management',\n",
       " 'Industry_Machinery',\n",
       " 'Industry_Power',\n",
       " 'Industry_Publishing & Newspapers',\n",
       " 'Industry_Real Estate (General/Diversified)',\n",
       " 'Industry_Real Estate (Operations & Services)',\n",
       " 'Industry_Recreation',\n",
       " 'Industry_Restaurant/Dining',\n",
       " 'Industry_Retail (Automotive)',\n",
       " 'Industry_Retail (General)',\n",
       " 'Industry_Semiconductor',\n",
       " 'Industry_Software (Entertainment)',\n",
       " 'Industry_Software (Internet)',\n",
       " 'Industry_Software (System & Application)',\n",
       " 'Industry_Telecom. Equipment',\n",
       " 'Industry_Telecom. Services',\n",
       " 'Industry_Transportation',\n",
       " 'Industry_Transportation (Railroads)',\n",
       " 'Region_Asia-Pacific',\n",
       " 'Region_EMEA',\n",
       " 'Region_Emerging Markets',\n",
       " 'Region_North America',\n",
       " 'EV/EBITDAR&D2',\n",
       " 'LastFundingType__Angel',\n",
       " 'LastFundingType__Convertible Note',\n",
       " 'LastFundingType__Corporate Round',\n",
       " 'LastFundingType__Debt Financing',\n",
       " 'LastFundingType__Equity Crowdfunding',\n",
       " 'LastFundingType__Grant',\n",
       " 'LastFundingType__Initial Coin Offering',\n",
       " 'LastFundingType__Non-equity Assistance',\n",
       " 'LastFundingType__Post-IPO Debt',\n",
       " 'LastFundingType__Post-IPO Equity',\n",
       " 'LastFundingType__Post-IPO Secondary',\n",
       " 'LastFundingType__Pre-Seed',\n",
       " 'LastFundingType__Private Equity',\n",
       " 'LastFundingType__Product Crowdfunding',\n",
       " 'LastFundingType__Secondary Market',\n",
       " 'LastFundingType__Seed',\n",
       " 'LastFundingType__Series A',\n",
       " 'LastFundingType__Series B',\n",
       " 'LastFundingType__Series C',\n",
       " 'LastFundingType__Series D',\n",
       " 'LastFundingType__Series E',\n",
       " 'LastFundingType__Series F',\n",
       " 'LastFundingType__Series G',\n",
       " 'LastFundingType__Series H',\n",
       " 'LastFundingType__Series I',\n",
       " 'LastFundingType__Series J',\n",
       " 'LastFundingType__Undisclosed',\n",
       " 'LastFundingType__Venture - Series Unknown',\n",
       " 'Norm Total Funding',\n",
       " 'Norm EV/Sales',\n",
       " 'Norm ROE',\n",
       " 'Norm Expected growth 5 years',\n",
       " 'Norm Forward PE',\n",
       " 'Norm % of Money Losing firms (Trailing)',\n",
       " 'Norm Price/Sales',\n",
       " 'Norm Net Margin',\n",
       " 'Norm Pre-tax Operating Margin',\n",
       " 'Norm PBV',\n",
       " 'Norm EV/ Invested Capital',\n",
       " 'Norm ROIC',\n",
       " 'Norm EV/EBITDAR&D',\n",
       " 'Norm EV/EBITDA',\n",
       " 'Norm EV/EBIT',\n",
       " 'Norm EV/EBIT (1-t)',\n",
       " 'Norm EV/EBITDA3',\n",
       " 'Norm EV/EBIT4',\n",
       " 'Norm EV/EBIT (1-t)5',\n",
       " 'Norm Current PE',\n",
       " 'Norm Trailing PE',\n",
       " 'Norm Aggregate Mkt Cap/ Net Income (all firms)',\n",
       " 'Norm Aggregate Mkt Cap/ Trailing Net Income (only money making firms)',\n",
       " 'Norm PEG Ratio',\n",
       " 'normalized_valuation']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mappin from feature to categorical variable - otherwise big problema\n",
    "feature_to_category = {}\n",
    "for category, dummy_columns in categorical_variables.items():\n",
    "    for feature in dummy_columns:\n",
    "        feature_to_category[feature] = category\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# get vars means, mins, and maxs\n",
    "feature_means = X_train.mean()\n",
    "feature_mins = X_train.min()\n",
    "feature_maxs = X_train.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  variables to be auto filled based on industry name - STILL YOU NEED TO WORK \n",
    "auto_fill_variables = [\n",
    "    'Net Margin', 'Norm EV/Sales', 'Pre-tax Operating Margin', 'PBV', 'Norm ROE',\n",
    "    'EV/ Invested Capital', 'ROIC', 'EV/EBITDAR&D', 'EV/EBITDA', 'EV/EBIT',\n",
    "    'EV/EBIT (1-t)', 'EV/EBITDAR&D2', 'EV/EBITDA3', 'EV/EBIT4', 'EV/EBIT (1-t)5',\n",
    "    'Norm % of Money Losing firms (Trailing)', 'Current PE', 'Trailing PE', 'Norm Forward PE',\n",
    "    'Aggregate Mkt Cap/ Trailing Net Income (only money making firms)', 'Norm Expected growth 5 years'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JacopoBinati\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.5157 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 2/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0710 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 3/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0317 - val_loss: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 4/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0045 - learning_rate: 0.0010\n",
      "Epoch 5/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 6/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 7/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0042 - learning_rate: 0.0010\n",
      "Epoch 8/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0044 - learning_rate: 0.0010\n",
      "Epoch 9/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 10/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 11/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 12/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 13/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 14/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 15/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 16/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0042 - learning_rate: 0.0010\n",
      "Epoch 17/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 18/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 19/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 20/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 21/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 22/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 23/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 24/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 25/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 26/500\n",
      "\u001b[1m357/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 27/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 28/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 29/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 30/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 31/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 32/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 33/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 34/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 35/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 36/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 37/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 38/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 39/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 40/500\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 41/500\n",
      "\u001b[1m348/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0040 - learning_rate: 2.0000e-04\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n"
     ]
    }
   ],
   "source": [
    "# build and train the model - THIS IS ACTUALLY REALLY NICE! HAPPY\n",
    "def build_and_train_enhanced_model(X_train, y_train, learning_rate=0.001, batch_size=32, epochs=500, scaler=None):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(512, input_dim=X_train.shape[1], activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = Nadam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau( monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=PATIENCE,\n",
    "        min_lr=MIN_LR,\n",
    "        verbose=1)\n",
    "     \n",
    "    history = model.fit(X_train, y_train, \n",
    "        validation_data=(X_val, y_val), \n",
    "        epochs=EPOCHS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        callbacks=[early_stopping, reduce_lr], \n",
    "        verbose=1)\n",
    "\n",
    "    return model, history, scaler\n",
    "\n",
    "# train & save\n",
    "model, history, scaler = build_and_train_enhanced_model(X_train_scaled, y_train, scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, scaler, and feature means have been saved.\n"
     ]
    }
   ],
   "source": [
    "# update  saving code:\n",
    "save_model(model, 'optimized_model.h5')\n",
    "joblib.dump(scaler, 'scaler.save')\n",
    "joblib.dump(feature_means, 'feature_means.save')\n",
    "print(\"Model, scaler, and feature means have been saved.\")\n",
    "\n",
    "# load the model, scaler, and feature means\n",
    "model = load_model('optimized_model.h5')\n",
    "scaler = joblib.load('scaler.save')\n",
    "feature_means = joblib.load('feature_means.save')\n",
    "\n",
    "# Load the column names (features)\n",
    "feature_columns = feature_means.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct categorical variables and mappings\n",
    "categorical_variables = {\n",
    "    'Industry': [col for col in feature_columns if col.startswith('Industry_')],\n",
    "    'Region': [col for col in feature_columns if col.startswith('Region_')],\n",
    "    'Last Funding Type': [col for col in feature_columns if col.startswith('LastFundingType__')],\n",
    "    'All Funding Type': [col for col in feature_columns if col.startswith('FundingType__')],\n",
    "    'size of the company': [col for col in feature_columns if col.startswith('NumberEmployees__')]\n",
    "}\n",
    "# here create mapping from feature to categorical variable\n",
    "feature_to_category = {}\n",
    "for category, dummy_columns in categorical_variables.items():\n",
    "    for feature in dummy_columns:\n",
    "        feature_to_category[feature] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess new input data\n",
    "def preprocess_input(input_data):\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    \n",
    "    for col in X.columns:\n",
    "        if col not in input_df.columns:\n",
    "            if col in feature_means:\n",
    "                input_df[col] = feature_means[col]\n",
    "            else:\n",
    "                input_df[col] = 0  \n",
    "    \n",
    "    input_df = input_df[X.columns] # reorder columns to match the training data structure\n",
    "    input_scaled = scaler.transform(input_df)  # scale the input data using the pre-fitted scaler\n",
    "    \n",
    "    return input_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions using the trained model\n",
    "def predict(input_data):\n",
    "    # handle missing Total Funding Amount\n",
    "    if 'Total Funding Amount (in USD)' not in input_data:\n",
    "        print(\"Warning: Feature 'Total Funding Amount (in USD)' is missing. Using mean value.\")\n",
    "        input_data['Total Funding Amount (in USD)'] = feature_means['Total Funding Amount (in USD)']\n",
    "    \n",
    "    # \n",
    "    preprocessed_data = preprocess_input(input_data)\n",
    "    \n",
    "    # \n",
    "    raw_prediction = model.predict(preprocessed_data)[0][0]\n",
    "    \n",
    "    # \n",
    "    if 'normalized_valuation' in feature_mins and 'normalized_valuation' in feature_maxs:\n",
    "        min_val = feature_mins['normalized_valuation']\n",
    "        max_val = feature_maxs['normalized_valuation']\n",
    "        \n",
    "        # \n",
    "        denormalized_prediction = raw_prediction * (max_val - min_val) + min_val\n",
    "        \n",
    "        print(f\"Normalized Predicted Valuation: {raw_prediction:.6f}\")\n",
    "        print(f\"Denormalized Predicted Valuation: ${denormalized_prediction:,.2f}\")\n",
    "    else:\n",
    "        # Fallback behavior in case 'normalized_valuation' is missing\n",
    "        print(\"Warning: 'normalized_valuation' not found in feature_mins or feature_maxs. Using raw prediction.\")\n",
    "        denormalized_prediction = raw_prediction\n",
    "        \n",
    "        print(f\"Raw Predicted Valuation (no denormalization applied): {raw_prediction:.6f}\")\n",
    "    \n",
    "    return denormalized_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input():\n",
    "    input_data = {}\n",
    "    input_data['Number of Founders'] = int(input(\"Enter Number of Founders: \"))\n",
    "    input_data['Number of Funding Rounds'] = int(input(\"Enter Number of Funding Rounds: \"))\n",
    "    input_data['Last Funding Amount (in USD)'] = float(input(\"Enter Last Funding Amount (in USD): \"))\n",
    "    input_data['Last Equity Funding Amount (in USD)'] = float(input(\"Enter Last Equity Funding Amount (in USD): \"))\n",
    "    input_data['Total Equity Funding Amount (in USD)'] = float(input(\"Enter Total Equity Funding Amount (in USD): \"))\n",
    "    input_data['Total Funding Amount (in USD)'] = float(input(\"Enter Total Funding Amount (in USD): \"))\n",
    "    input_data['Number of Investors'] = int(input(\"Enter Number of Investors: \"))\n",
    "    input_data['Last Funding Year'] = int(input(\"Enter Last Funding Year: \"))\n",
    "    input_data['Founded Year'] = int(input(\"Enter Founded Year: \"))\n",
    "    \n",
    "    # Get categorical variables\n",
    "    status = input(\"Enter Status (Private/Public): \")\n",
    "    if status.lower() == \"private\":\n",
    "        input_data['Status__Private'] = 1.0\n",
    "        input_data['Status__Public'] = 0.0\n",
    "    else:\n",
    "        input_data['Status__Private'] = 0.0\n",
    "        input_data['Status__Public'] = 1.0\n",
    "        \n",
    "    company_type = input(\"Enter Company Type (For Profit/Non-profit): \")\n",
    "    if company_type.lower() == \"for profit\":\n",
    "        input_data['CompanyType__For Profit'] = 1.0\n",
    "        input_data['CompanyType__Non-profit'] = 0.0\n",
    "    else:\n",
    "        input_data['CompanyType__For Profit'] = 0.0\n",
    "        input_data['CompanyType__Non-profit'] = 1.0\n",
    "        \n",
    "    # Get list of employees\n",
    "    employees = input(\"Enter Number of Employees (separate with commas): \").split(',')\n",
    "    employees = [employee.strip() for employee in employees]\n",
    "    for employee in employees:\n",
    "        input_data[f'NumberEmployees__{employee}'] = 1.0\n",
    "        \n",
    "    # Get list of funding types\n",
    "    funding_types = input(\"Enter Funding Types (separate with commas): \").split(',')\n",
    "    funding_types = [funding_type.strip() for funding_type in funding_types]\n",
    "    for funding_type in funding_types:\n",
    "        input_data[f'FundingType__{funding_type}'] = 1.0\n",
    "        \n",
    "    # Get list of last funding types\n",
    "    last_funding_types = input(\"Enter Last Funding Types (separate with commas): \").split(',')\n",
    "    last_funding_types = [last_funding_type.strip() for last_funding_type in last_funding_types]\n",
    "    for last_funding_type in last_funding_types:\n",
    "        input_data[f'LastFundingType__{last_funding_type}'] = 1.0\n",
    "        \n",
    "    # Get list of regions\n",
    "    regions = input(\"Enter Regions (separate with commas): \").split(',')\n",
    "    regions = [region.strip() for region in regions]\n",
    "    for region in regions:\n",
    "        input_data[f'Region__{region}'] = 1.0\n",
    "        \n",
    "    # Get list of industries\n",
    "    industries = input(\"Enter Industries (separate with commas): \").split(',')\n",
    "    industries = [industry.strip() for industry in industries]\n",
    "    for industry in industries:\n",
    "        input_data[f'Industry__{industry}'] = 1.0\n",
    "        \n",
    "    # Compute Norm Total Funding\n",
    "    total_funding = input_data['Last Equity Funding Amount (in USD)'] + input_data['Total Equity Funding Amount (in USD)'] + input_data['Total Funding Amount (in USD)']\n",
    "    min_funding = 0\n",
    "    max_funding = 10000000000000  # Assuming a maximum funding of 1 billion USD\n",
    "    input_data['Norm Total Funding'] = (total_funding - min_funding) / (max_funding - min_funding)\n",
    "    \n",
    "    def compute_variables(input_data, df, selected_regions, selected_industries):\n",
    "    # Compute other variables\n",
    "        for region in selected_regions:\n",
    "            for industry in selected_industries:\n",
    "            # Filter the DataFrame for the selected region and industry\n",
    "                filtered_df = df[(df[f'Region_{region}'] == 1.0) & (df[f'Industry_{industry}'] == 1.0)]\n",
    "                \n",
    "                # Compute average values for each variable\n",
    "                avg_ev_sales = filtered_df[f'{region}__{industry}_EV_Sales'].mean()\n",
    "                avg_roe = filtered_df[f'{region}__{industry}_ROE'].mean()\n",
    "                avg_expected_growth = filtered_df[f'{region}__{industry}_Expected_Growth'].mean()\n",
    "                avg_forward_pe = filtered_df[f'{region}__{industry}_Forward_PE'].mean()\n",
    "                avg_money_losing_firms = filtered_df[f'{region}__{industry}_Money_Losing_Firms'].mean()\n",
    "                avg_price_sales = filtered_df[f'{region}__{industry}_Price_Sales'].mean()\n",
    "                avg_net_margin = filtered_df[f'{region}__{industry}_Net_Margin'].mean()\n",
    "                avg_pre_tax_operating_margin = filtered_df[f'{region}__{industry}_Pre_Tax_Operating_Margin'].mean()\n",
    "                avg_pbv = filtered_df[f'{region}__{industry}_PBV'].mean()\n",
    "                avg_ev_invested_capital = filtered_df[f'{region}__{industry}_EV_Invested_Capital'].mean()\n",
    "                avg_roic = filtered_df[f'{region}__{industry}_ROIC'].mean()\n",
    "                avg_ev_ebitdar_d = filtered_df[f'{region}__{industry}_EV_EBITDAR_D'].mean()\n",
    "                avg_ev_ebitda = filtered_df[f'{region}__{industry}_EV_EBITDA'].mean()\n",
    "                avg_ev_ebit = filtered_df[f'{region}__{industry}_EV_EBIT'].mean()\n",
    "                avg_ev_ebit_1_t = filtered_df[f'{region}__{industry}_EV_EBIT_1_T'].mean()\n",
    "                avg_ev_ebitda3 = filtered_df[f'{region}__{industry}_EV_EBITDA3'].mean()\n",
    "                avg_ev_ebit4 = filtered_df[f'{region}__{industry}_EV_EBIT4'].mean()\n",
    "                avg_ev_ebit_1_t5 = filtered_df[f'{region}__{industry}_EV_EBIT_1_T5'].mean()\n",
    "                avg_current_pe = filtered_df[f'{region}__{industry}_Current_PE'].mean()\n",
    "                avg_trailing_pe = filtered_df[f'{region}__{industry}_Trailing_PE'].mean()\n",
    "                avg_aggregate_mkt_cap_net_income = filtered_df[f'{region}__{industry}_Aggregate_Mkt_Cap_Net_Income'].mean()\n",
    "                avg_aggregate_mkt_cap_trailing_net_income = filtered_df[f'{region}__{industry}_Aggregate_Mkt_Cap_Trailing_Net_Income'].mean()\n",
    "                avg_peg_ratio = filtered_df[f'{region}__{industry}_PEG_Ratio'].mean()\n",
    "                \n",
    "                input_data[f'Norm EV/Sales'] = avg_ev_sales\n",
    "                input_data[f'Norm ROE'] = avg_roe\n",
    "                input_data[f'Norm Expected growth 5 years'] = avg_expected_growth\n",
    "                input_data[f'Norm Forward PE'] = avg_forward_pe\n",
    "                input_data[f'Norm % of Money Losing firms (Trailing)'] = avg_money_losing_firms\n",
    "                input_data[f'Price/Sales'] = avg_price_sales\n",
    "                input_data[f'Net Margin'] = avg_net_margin\n",
    "                input_data[f'Pre-tax Operating Margin'] = avg_pre_tax_operating_margin\n",
    "                input_data[f'PBV'] = avg_pbv\n",
    "                input_data[f'EV/ Invested Capital'] = avg_ev_invested_capital\n",
    "                input_data[f'ROIC'] = avg_roic\n",
    "                input_data[f'EV/EBITDAR&D'] = avg_ev_ebitdar_d\n",
    "                input_data[f'EV/EBITDA'] = avg_ev_ebitda\n",
    "                input_data[f'EV/EBIT'] = avg_ev_ebit\n",
    "                input_data[f'EV/EBIT (1-t)'] = avg_ev_ebit_1_t\n",
    "                input_data[f'EV/EBITDA3'] = avg_ev_ebitda3\n",
    "                input_data[f'EV/EBIT4'] = avg_ev_ebit4\n",
    "                input_data[f'EV/EBIT (1-t)5'] = avg_ev_ebit_1_t5\n",
    "                input_data[f'Current PE'] = avg_current_pe\n",
    "                input_data[f'Trailing PE'] = avg_trailing_pe\n",
    "                input_data[f'Aggregate Mkt Cap/ Net Income (all firms)'] = avg_aggregate_mkt_cap_net_income\n",
    "                input_data[f'Aggregate Mkt Cap/ Trailing Net Income (only money making firms)'] = avg_aggregate_mkt_cap_trailing_net_income\n",
    "                input_data[f'PEG Ratio'] = avg_peg_ratio\n",
    "\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Provide input for each feature (or press Enter to use mean value):\n",
      "\n",
      "Select size of the company(s) from the list (you can select multiple):\n",
      "1. NumberEmployees__1-10\n",
      "2. NumberEmployees__10001+\n",
      "3. NumberEmployees__1001-5000\n",
      "4. NumberEmployees__101-250\n",
      "5. NumberEmployees__11-50\n",
      "6. NumberEmployees__251-500\n",
      "7. NumberEmployees__5001-10000\n",
      "8. NumberEmployees__501-1000\n",
      "9. NumberEmployees__51-100\n",
      "\n",
      "Select All Funding Type(s) from the list (you can select multiple):\n",
      "1. FundingType__Angel\n",
      "2. FundingType__Convertible Note\n",
      "3. FundingType__Corporate Round\n",
      "4. FundingType__Debt Financing\n",
      "5. FundingType__Equity Crowdfunding\n",
      "6. FundingType__Grant\n",
      "7. FundingType__Initial Coin Offering\n",
      "8. FundingType__Non-equity Assistance\n",
      "9. FundingType__Post-IPO Debt\n",
      "10. FundingType__Post-IPO Equity\n",
      "11. FundingType__Post-IPO Secondary\n",
      "12. FundingType__Pre-Seed\n",
      "13. FundingType__Private Equity\n",
      "14. FundingType__Product Crowdfunding\n",
      "15. FundingType__Secondary Market\n",
      "16. FundingType__Seed\n",
      "17. FundingType__Series A\n",
      "18. FundingType__Series B\n",
      "19. FundingType__Series C\n",
      "20. FundingType__Series D\n",
      "21. FundingType__Series E\n",
      "22. FundingType__Series F\n",
      "23. FundingType__Series G\n",
      "24. FundingType__Series H\n",
      "25. FundingType__Series I\n",
      "26. FundingType__Series J\n",
      "27. FundingType__Undisclosed\n",
      "28. FundingType__Venture - Series Unknown\n",
      "\n",
      "Select Industry(s) from the list (you can select multiple):\n",
      "1. Aerospace/Defense\n",
      "2. Air Transport\n",
      "3. Apparel\n",
      "4. Auto & Truck\n",
      "5. Auto Parts\n",
      "6. Bank (Money Center)\n",
      "7. Banks (Regional)\n",
      "8. Beverage (Soft)\n",
      "9. Brokerage & Investment Banking\n",
      "10. Building Materials\n",
      "11. Business & Consumer Services\n",
      "12. Chemical (Basic)\n",
      "13. Chemical (Diversified)\n",
      "14. Chemical (Specialty)\n",
      "15. Coal & Related Energy\n",
      "16. Computer Services\n",
      "17. Computers/Peripherals\n",
      "18. Diversified\n",
      "19. Drugs (Biotechnology)\n",
      "20. Drugs (Pharmaceutical)\n",
      "21. Education\n",
      "22. Electrical Equipment\n",
      "23. Electronics (Consumer & Office)\n",
      "24. Electronics (General)\n",
      "25. Engineering/Construction\n",
      "26. Entertainment\n",
      "27. Environmental & Waste Services\n",
      "28. Farming/Agriculture\n",
      "29. Financial Svcs. (Non-bank & Insurance)\n",
      "30. Food Processing\n",
      "31. Food Wholesalers\n",
      "32. Green & Renewable Energy\n",
      "33. Healthcare Support Services\n",
      "34. Heathcare Information and Technology\n",
      "35. Homebuilding\n",
      "36. Hotel/Gaming\n",
      "37. Household Products\n",
      "38. Information Services\n",
      "39. Insurance (General)\n",
      "40. Investments & Asset Management\n",
      "41. Machinery\n",
      "42. Power\n",
      "43. Publishing & Newspapers\n",
      "44. Real Estate (General/Diversified)\n",
      "45. Real Estate (Operations & Services)\n",
      "46. Recreation\n",
      "47. Restaurant/Dining\n",
      "48. Retail (Automotive)\n",
      "49. Retail (General)\n",
      "50. Semiconductor\n",
      "51. Software (Entertainment)\n",
      "52. Software (Internet)\n",
      "53. Software (System & Application)\n",
      "54. Telecom. Equipment\n",
      "55. Telecom. Services\n",
      "56. Transportation\n",
      "57. Transportation (Railroads)\n",
      "\n",
      "Select Region(s) from the list (you can select multiple):\n",
      "1. Asia-Pacific\n",
      "2. EMEA\n",
      "3. Emerging Markets\n",
      "4. North America\n",
      "\n",
      "Select Last Funding Type(s) from the list (you can select multiple):\n",
      "1. LastFundingType__Angel\n",
      "2. LastFundingType__Convertible Note\n",
      "3. LastFundingType__Corporate Round\n",
      "4. LastFundingType__Debt Financing\n",
      "5. LastFundingType__Equity Crowdfunding\n",
      "6. LastFundingType__Grant\n",
      "7. LastFundingType__Initial Coin Offering\n",
      "8. LastFundingType__Non-equity Assistance\n",
      "9. LastFundingType__Post-IPO Debt\n",
      "10. LastFundingType__Post-IPO Equity\n",
      "11. LastFundingType__Post-IPO Secondary\n",
      "12. LastFundingType__Pre-Seed\n",
      "13. LastFundingType__Private Equity\n",
      "14. LastFundingType__Product Crowdfunding\n",
      "15. LastFundingType__Secondary Market\n",
      "16. LastFundingType__Seed\n",
      "17. LastFundingType__Series A\n",
      "18. LastFundingType__Series B\n",
      "19. LastFundingType__Series C\n",
      "20. LastFundingType__Series D\n",
      "21. LastFundingType__Series E\n",
      "22. LastFundingType__Series F\n",
      "23. LastFundingType__Series G\n",
      "24. LastFundingType__Series H\n",
      "25. LastFundingType__Series I\n",
      "26. LastFundingType__Series J\n",
      "27. LastFundingType__Undisclosed\n",
      "28. LastFundingType__Venture - Series Unknown\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Industry'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\JacopoBinati\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Industry'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m         input_data \u001b[38;5;241m=\u001b[39m input_for_prediction()\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mYour input data for prediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(input_data)\n",
      "Cell \u001b[1;32mIn[30], line 70\u001b[0m, in \u001b[0;36minput_for_prediction\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Check if industry and region data is available, otherwise use global mean\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_industries \u001b[38;5;129;01mand\u001b[39;00m selected_regions:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Filter dataframe for selected industries and regions\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     industry_data \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndustry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(selected_industries)) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(selected_regions))]\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m selected_industries:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# Filter only by industry if no region is selected\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     industry_data \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndustry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(selected_industries)]\n",
      "File \u001b[1;32mc:\\Users\\JacopoBinati\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\JacopoBinati\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Industry'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        input_data = input_for_prediction()\n",
    "        print(\"\\nYour input data for prediction:\")\n",
    "        print(input_data)\n",
    "        proceed = input(\"\\nDo you want to input another set of data? (y/n): \").strip().lower()\n",
    "        if proceed != 'y':\n",
    "            print(\"Exiting the input session.\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
